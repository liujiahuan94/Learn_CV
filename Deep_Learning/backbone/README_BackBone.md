# Backbone细节介绍

## VGG模型

1. **VGG模型论文原文[链接](https://arxiv.org/pdf/1409.1556)**
2. **论文创新点**

- 模型结构设计
  - 首次采用小卷积核，堆叠使用卷积核，如2个3×3卷积核等效5×5
  - 使用pooling操作减半分辨率，但是将通道数翻倍来弥补信息损失

* 训练技巧上

  * 增加了尺度扰动，按比例缩放图片至最小边S，随机位置裁剪出224×224区域
  * 预训练模型初始化，利用浅层模型初始化深层模型，用小尺度模型初始化大尺度模型
* 测试技巧上

  * 多尺度测试，图片等比例缩放至最短边为Q，设置3个Q，对图片进行预测，取平均；
  * 稠密测试：将FC层转换为卷积操作，变为全卷积网络，实现任意尺度图片输入；
  * Multi-Crop测试，借鉴AlexNet与GoogLeNet对图片进行Multi-crop，裁剪大小为224*224，并水平翻转1张图，缩放至3种尺寸，然后每种尺寸裁剪出50张图片；
  * 多尺度测试，等比例缩放图像至三种尺寸；

3. **优缺点分析**

- 优点
  - VGG网络的结构非常简洁，整个网络都使用了同样的3×3卷积核尺寸和最大池化尺寸(2×2)；
  - 几个小滤波器(3×3)卷积层的组合比一个大滤波器(5×5或7×7)卷积层好；
  - 验证了通过不断加深网络结构可以提升性能。
- 缺点
  - VGG模型使用了更多的参数，尤其是全连接层，第一个FC层的参数高达1.03亿，导致模型运算较慢。

4. **心得**

VGG模型结构简单，原理直白易懂，代码编写也比较简单，能够很快搭建模型并开始训练，对新手友好。尤其是VGG模型没有归一化处理的BN层，不会出现训练和测试时BN层参数不同带来的结果差异。其次，VGG模型结构虽然简单，但是也很有效，尤其是对于工业场景中图片内容变化较小的情况，VGG模型的容量足够应对多数工业图片分类场景，很适合在项目前期做能力摸底验证工作。

## GoogleNet模型

1. **GoogleNet模型论文原文[链接](https://arxiv.org/pdf/1409.4842)**
2. 论文创新点

- 模型结构设计
